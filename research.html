<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Yuer Tang - Goal Inference Project</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
      blockquote {
        margin-left: 0;
        font-style: italic;
        font-size: 1.1em;
        color: #555;
        border-left: 5px solid #ccc;
        padding-left: 15px;
      }
      .image-gallery img {
        display: inline-block;
        width: 45%;
        margin-right: 5%;
        vertical-align: middle;
      }
      .image-gallery img:last-child {
        margin-right: 0;
      }
      p {
        clear: both;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="index.html" target="_blank">Internships & Research</a></h1>
        <div class="nav-list">
          <a href="index.html" class="nav-link">Home Page</a>
          <a href="projects.html" class="nav-link">Projects</a>
        </div>
      </header>

      <section>
        <h2>TVMs and Understanding the latent representation </h2>
        <p>Despite the widespread success of artificial intelligence (AI), the fundamental question remains: how exactly do neural networks (NNs) store, interpret, and retrieve, i.e., learn, information? Exploring this question creates new opportunities to advance explainable AI and helps us develop enhanced physics-aware architectures. In particular, this research will investigate how dynamical systems theory can be used to explore and understand latent representations of NNs, providing deeper insights into their learning processes and potential explainability.		


          Recent studies suggest that traveling wave models (TVMs) offer an alternative approach that may address these limitations. In particular, Kim et al. demonstrated that incorporating traveling waves into basic recurrent neural networks enhances sequence learning by encoding the recent past, providing a biologically plausible mechanism for memory in neural systems [1]. These findings, along with the distinctive properties of the ‘wave’ concept, motivate this study to explore whether TVMs can improve interpretability and physical consistency across various complex physical systems. Specifically, we focus on systems where the underlying patterns inherently involve ‘rate of change’ and continuous dynamics—principles that align naturally with TVMs—such as watershed hydrology [2], ultrafast optical lasers, and protein interaction networks.				
          The latent space produced by these models will be analyzed to uncover patterns, features, and relationships within these complex systems. This approach will be empirically validated through both synthetic dynamical systems tasks and real-world data, leveraging insights from both traveling wave mechanisms and hydrological concept formation studies. 
          References
          [1] Keller, T. Anderson, et al. "Traveling Waves Encode the Recent Past and Enhance Sequence Learning." The Twelfth International Conference on Learning Representations, 2024, https://openreview.net/forum?id=p4S5.
          [2] Beven, Keith J., et al. "Deep Learning, Hydrological Processes, and the Uniqueness of Place." Hydrology and Earth System Sciences, vol. 26, 2022, pp. 3079–3090. Copernicus Publications, https://hess.copernicus.org/articles/26/3079/2022/.
          </p>
      </section>

      <section>
        <h2>Latent Generation System</h2>
      </section>

      <section>
        <h2>Goal Inference in a Grid World Environment</h2>
        <p>This project aims to model and infer a player's goal within a grid-based environment using <strong>Bayesian inference</strong> and <strong>value iteration</strong>. The core idea is to understand how an agent can predict the goal of another agent based on observed actions and state transitions, utilizing principles from reinforcement learning.</p>

        <p>The project consists of two main components:</p>


        <h3>Goal Inference Map (GIM)</h3>
        <ul>
          <li>For each potential goal in the environment, a <strong>policy</strong> is generated using <strong>value iteration</strong> to estimate the optimal actions the agent should take to reach the goal.</li>
          <li>This policy helps compute the likelihood of observed actions, indicating how probable it is for the agent to be pursuing a specific goal based on its behavior.</li>
        </ul>

        <h3>Posterior Update Mechanism</h3>
        <p>Given observed actions, a Bayesian posterior distribution is updated over possible goals. This process helps refine the prediction of which goal the agent is likely aiming for. The <strong>posterior</strong> is updated by comparing the observed action to the predicted optimal actions (from the GIM) for each goal, adjusting the likelihoods based on a decay factor.</p>

        <p>The environment is represented by a grid with predefined obstacles (blocks) and potential goals. Using this framework, the model can predict and update the probability distribution of the agent’s goal as it navigates the environment.</p>

        <div class="image-gallery">
          <img src="path_to_goal_inference_diagram.jpg" alt="Goal Inference Diagram">
          <img src="path_to_gim_diagram1.jpg" alt="Goal Inference Map">
          <img src="path_to_gim_diagram2.jpg" alt="Posterior Update Mechanism">
        </div>
      </section>

      <footer>
        <p>© 2024 Yuer Tang. All rights reserved.</p>
      </footer>
    </div>

    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
